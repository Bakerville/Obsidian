When working with Spark, the driver program convert yout Spark application into one or more Spark jobs. It then transforms each job in to a DAG. 

This below image represents the Spark's execution plan, where each node within a DAG could be a single or multiple Spark stages.

![[Spark Job.png]]

[[Spark Application and SparkSession]]
